{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TunningANNforMNIST.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcPG6OmOD-BU"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdFIKLFHA_Cv",
        "outputId": "64a9cdaa-19d3-433f-dd3a-dd55a6352f1f"
      },
      "source": [
        "!pip install scikit-optimize\r\n",
        "from skopt import BayesSearchCV\r\n",
        "from skopt.space import Real, Categorical, Integer\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cufgjv0ls9X8"
      },
      "source": [
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, space_eval"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7hIVYIpBoBl"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7781m6n6Bsmb"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMkozclOEWnz",
        "outputId": "9ec8472c-45eb-4c44-fd11-e5c301ffb436"
      },
      "source": [
        "!pip install tensorflow-datasets==3.2.1\r\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-datasets==3.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/c9/d97bdf931edbae9aebc767633d088bd674136d5fe7587ef693b7cb6a1883/tensorflow_datasets-3.2.1-py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (2.23.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.26.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.19.5)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (20.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.12.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.15.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (4.41.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==3.2.1) (2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==3.2.1) (2.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==3.2.1) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==3.2.1) (51.1.1)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Successfully installed tensorflow-datasets-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D52vhmeeFBDJ"
      },
      "source": [
        "for ex_dict in ds_numpy:\r\n",
        "  print(ex_dict['image'])\r\n",
        "  #print(ex_dict['labels'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDENkgBjECDs"
      },
      "source": [
        "## DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pctXTx24EKKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4511e8e2-3aee-4055-bb6b-2b17a3458502"
      },
      "source": [
        "trainset, testset = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y6chbymIBC8"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(trainset[0], trainset[1], test_size=0.2, random_state=12345)\r\n",
        "X_train, X_val = X_train / 255.0, X_val / 255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Q_l3_1Hrpq"
      },
      "source": [
        "X_train, X_train_early_stop, y_train, y_train_early_stop = train_test_split(X_train, y_train, test_size=0.05, random_state=1234)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulroEU-6EFkW"
      },
      "source": [
        "## TUNNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0OwtS3GSxIK"
      },
      "source": [
        " params_grid = {'layers_': hp.choice('layers_', [2, 3, 4, 5, 6, 7, 8, 9, 10]),\r\n",
        "                'learning_rate': hp.uniform('learning_rate', 0.00001, 0.1),\r\n",
        "                'neurons_': hp.quniform('neurons_', 10, 500, 1),\r\n",
        "                'dropout': hp.uniform('dropout', .25,.75)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTrmHYOzCW1n"
      },
      "source": [
        "def build_model(layers_=2, neurons_=10, learning_rate=0.001):\r\n",
        "\r\n",
        "  model = keras.models.Sequential()\r\n",
        "  model.add(layers.Flatten())\r\n",
        "\r\n",
        "  for i in range(layers_):\r\n",
        "    model.add(layers.BatchNormalization())\r\n",
        "    model.add(layers.Dense(neurons_, \r\n",
        "                           activation=keras.activations.elu, \r\n",
        "                           kernel_initializer=keras.initializers.he_normal, \r\n",
        "                           use_bias=False))\r\n",
        "\r\n",
        "  model.add(layers.Dense(10, \r\n",
        "                         activation=keras.activations.softmax, \r\n",
        "                         kernel_initializer=keras.initializers.he_normal))\r\n",
        "\r\n",
        "  model.compile(optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9),\r\n",
        "               loss=keras.losses.sparse_categorical_crossentropy,\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2kfAjf0QOhU"
      },
      "source": [
        "keras_wrapper = keras.wrappers.scikit_learn.KerasClassifier(build_model, \r\n",
        "                                                            epochs=100,\r\n",
        "                                                            validation_split=0.5\r\n",
        "                                                            #validation_data=(X_train_early_stop, y_train_early_stop),\r\n",
        "                                                            #keras.callbacks.EarlyStopping(patience=5)\r\n",
        "                                                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "Ic2P9vrvRN0V",
        "outputId": "1a0efdb1-92d4-49a7-88ef-6424cc695228"
      },
      "source": [
        "opt = BayesSearchCV(\r\n",
        "    keras_wrapper,\r\n",
        "    {'layers_': Integer(1, 200),\r\n",
        "     'learning_rate': (1e-6, 1e-2, 'log-uniform'),\r\n",
        "     'neurons_': Integer(1, 8),\r\n",
        "     'epochs': [10, 15, 20, 25, 30],\r\n",
        "     'dropout': hp.uniform('dropout', .25,.75),\r\n",
        "    },\r\n",
        "    n_iter=32,\r\n",
        "    cv=3\r\n",
        ")\r\n",
        "\r\n",
        "fit_params = dict(callbacks=[keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)])\r\n",
        "\r\n",
        "opt.fit(X_train, y_train, **fit_params)\r\n",
        "\r\n",
        "print(\"val. score: %s\" % opt.best_score_)\r\n",
        "print(\"test score: %s\" % opt.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-213-ad03af042da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val. score: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'callbacks'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye-NbRMFns04"
      },
      "source": [
        "## Metod 2 using hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCtqPWhdZle4"
      },
      "source": [
        " params_grid = {'layers_': hp.choice('layers_', [2, 3, 4, 5, 6, 7, 8, 9, 10]),\r\n",
        "                'learning_rate': hp.uniform('learning_rate', 0.00001, 0.1),\r\n",
        "                'neurons_': hp.quniform('neurons_', 10, 500, 1),\r\n",
        "                'dropout': hp.uniform('dropout', 0,.75)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P201Ybpnxww"
      },
      "source": [
        "def objective(params):\r\n",
        "    \r\n",
        "    print('\\n', params)\r\n",
        "    \r\n",
        "    model = keras.models.Sequential()\r\n",
        "    model.add(layers.Flatten())\r\n",
        "\r\n",
        "    for i in range(params['layers_']):\r\n",
        "      model.add(layers.BatchNormalization())\r\n",
        "      model.add(layers.Dropout(rate=params['dropout']))\r\n",
        "      model.add(layers.Dense(int(params['neurons_']), \r\n",
        "                            activation=keras.activations.elu, \r\n",
        "                            kernel_initializer=keras.initializers.he_normal, \r\n",
        "                            use_bias=False))\r\n",
        "\r\n",
        "    model.add(layers.Dropout(rate=params['dropout']))\r\n",
        "    model.add(layers.Dense(10, \r\n",
        "                          activation=keras.activations.softmax, \r\n",
        "                          kernel_initializer=keras.initializers.he_normal))\r\n",
        "\r\n",
        "    model.compile(optimizer=keras.optimizers.SGD(lr=params['learning_rate'], momentum=0.9),\r\n",
        "                loss=keras.losses.sparse_categorical_crossentropy,\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    \r\n",
        "    model.fit(X_train,\r\n",
        "              y_train,\r\n",
        "              epochs=100,\r\n",
        "              validation_data=(X_train_early_stop, y_train_early_stop),\r\n",
        "              callbacks=keras.callbacks.EarlyStopping(patience=5),\r\n",
        "              verbose=0)\r\n",
        "\r\n",
        "    val_score = model.evaluate(X_val, y_val,\r\n",
        "                              verbose=0)\r\n",
        "    \r\n",
        "    return {\r\n",
        "        'loss':  val_score[0],\r\n",
        "        'accuracy': val_score[1],\r\n",
        "        'status': STATUS_OK,\r\n",
        "        'eval_time': time.time()\r\n",
        "        }"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYnDY02dt4jG",
        "outputId": "e9530d2c-e4dc-4bf2-e9d8-146fc3f0779e"
      },
      "source": [
        "# Benchmark\r\n",
        "objective({'learning_rate':0.01, 'layers_': 3, 'neurons_': 20})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " {'learning_rate': 0.01, 'layers_': 3, 'neurons_': 20}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9602500200271606,\n",
              " 'eval_time': 1610490715.472236,\n",
              " 'loss': 0.14226077497005463,\n",
              " 'status': 'ok'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6R46zAco9xr",
        "outputId": "b6f7fe03-2c00-4563-9bd2-fe3f897ab54f"
      },
      "source": [
        "trials = Trials()\r\n",
        "\r\n",
        "best = fmin(fn=objective,\r\n",
        "           space=params_grid,\r\n",
        "           algo=tpe.suggest,\r\n",
        "           max_evals=50,\r\n",
        "           trials=trials,\r\n",
        "           verbose=True,\r\n",
        "           show_progressbar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dropout': 0.6993786071256669, 'layers_': 9, 'learning_rate': 0.07182211369351536, 'neurons_': 241.0}\n",
            "{'dropout': 0.7467445253480463, 'layers_': 7, 'learning_rate': 0.07588864150403016, 'neurons_': 15.0}\n",
            "{'dropout': 0.6047989266235354, 'layers_': 5, 'learning_rate': 0.05052696295218311, 'neurons_': 465.0}\n",
            "{'dropout': 0.5447370240043307, 'layers_': 6, 'learning_rate': 0.016569990567445684, 'neurons_': 330.0}\n",
            "{'dropout': 0.551632370016417, 'layers_': 7, 'learning_rate': 0.017975063245596584, 'neurons_': 113.0}\n",
            "{'dropout': 0.5116187589185748, 'layers_': 5, 'learning_rate': 0.0901145877929097, 'neurons_': 230.0}\n",
            "{'dropout': 0.7018962570869532, 'layers_': 7, 'learning_rate': 0.015308609522616244, 'neurons_': 335.0}\n",
            " 12%|█▏        | 6/50 [15:52<1:51:58, 152.69s/it, best loss: 0.08728916198015213]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXxk9y5jrGDR"
      },
      "source": [
        "pickle.dump(trials, open(\"myfile.p\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHTSrxctdqht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}